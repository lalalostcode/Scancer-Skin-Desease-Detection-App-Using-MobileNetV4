{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ff25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using checkpoint: C:\\Local D\\Galeri Belajar\\Project\\Computer Vision\\scancer\\model\\best_model.pth type: pth\n",
      "Total params: 9806458\n",
      "Checkpoint size (MB): 37.922\n",
      "FLOPs: 949,824,320 -> 0.9498 GFLOPs\n",
      "Total params: 9806458\n",
      "Checkpoint size (MB): 37.922\n",
      "FLOPs: 949,824,320 -> 0.9498 GFLOPs\n",
      "Measuring on device: cpu\n",
      "Measuring on device: cpu\n",
      "Latency avg: 77.01 ms, Throughput: 13.0 img/s\n",
      "Latency avg: 77.01 ms, Throughput: 13.0 img/s\n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::conv2d         0.82%     798.100us        67.75%      66.188ms     551.567us           120  \n",
      "                           aten::convolution         1.26%       1.228ms        66.93%      65.390ms     544.917us           120  \n",
      "                          aten::_convolution         1.36%       1.330ms        65.68%      64.162ms     534.684us           120  \n",
      "                    aten::mkldnn_convolution        57.98%      56.638ms        59.02%      57.654ms     694.630us            83  \n",
      "                            aten::batch_norm         0.61%     596.400us        13.59%      13.279ms     138.328us            96  \n",
      "                aten::_batch_norm_impl_index         1.48%       1.441ms        12.98%      12.683ms     132.116us            96  \n",
      "                     aten::native_batch_norm        10.29%      10.049ms        11.29%      11.034ms     114.935us            96  \n",
      "          aten::scaled_dot_product_attention         0.06%      63.400us         7.39%       7.220ms     902.450us             8  \n",
      "    aten::_scaled_dot_product_attention_math         0.43%     418.800us         7.33%       7.156ms     894.525us             8  \n",
      "                           aten::thnn_conv2d         0.15%     148.000us         5.30%       5.178ms     139.932us            37  \n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 97.693ms\n",
      "\n",
      "Done.\n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::conv2d         0.82%     798.100us        67.75%      66.188ms     551.567us           120  \n",
      "                           aten::convolution         1.26%       1.228ms        66.93%      65.390ms     544.917us           120  \n",
      "                          aten::_convolution         1.36%       1.330ms        65.68%      64.162ms     534.684us           120  \n",
      "                    aten::mkldnn_convolution        57.98%      56.638ms        59.02%      57.654ms     694.630us            83  \n",
      "                            aten::batch_norm         0.61%     596.400us        13.59%      13.279ms     138.328us            96  \n",
      "                aten::_batch_norm_impl_index         1.48%       1.441ms        12.98%      12.683ms     132.116us            96  \n",
      "                     aten::native_batch_norm        10.29%      10.049ms        11.29%      11.034ms     114.935us            96  \n",
      "          aten::scaled_dot_product_attention         0.06%      63.400us         7.39%       7.220ms     902.450us             8  \n",
      "    aten::_scaled_dot_product_attention_math         0.43%     418.800us         7.33%       7.156ms     894.525us             8  \n",
      "                           aten::thnn_conv2d         0.15%     148.000us         5.30%       5.178ms     139.932us            37  \n",
      "--------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 97.693ms\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# optional libs\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    HAS_PT = True\n",
    "except Exception:\n",
    "    HAS_PT = False\n",
    "try:\n",
    "    from thop import profile as thop_profile\n",
    "    HAS_THOP = True\n",
    "except Exception:\n",
    "    HAS_THOP = False\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    HAS_INFO = True\n",
    "except Exception:\n",
    "    HAS_INFO = False\n",
    "\n",
    "import timm\n",
    "\n",
    "# CONFIG / auto-find checkpoint\n",
    "PROJECT_ROOT = Path(r\"C:\\Local D\\Galeri Belajar\\Project\\Computer Vision\\scancer\")\n",
    "pth_files = list(PROJECT_ROOT.rglob(\"*.pth\"))\n",
    "ptl_files = list(PROJECT_ROOT.rglob(\"*.ptl\")) + list(PROJECT_ROOT.rglob(\"*.pt\"))\n",
    "if pth_files:\n",
    "    CKPT = str(pth_files[0])\n",
    "    CKPT_TYPE = \"pth\"\n",
    "elif ptl_files:\n",
    "    CKPT = str(ptl_files[0])\n",
    "    CKPT_TYPE = \"ptl\"\n",
    "else:\n",
    "    raise FileNotFoundError(f\"No .pth or .ptl found under {PROJECT_ROOT} - place checkpoint or set CKPT manually\")\n",
    "\n",
    "print(\"Using checkpoint:\", CKPT, \"type:\", CKPT_TYPE)\n",
    "\n",
    "# model meta (adjust if needed for your training)\n",
    "MODEL_NAME = \"mobilenetv4_hybrid_medium.e500_r224_in1k\"\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SIZE = (3, 224, 224)  # (C,H,W)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def safe_load_state_dict_into(model, state):\n",
    "    # Try common checkpoint formats\n",
    "    try:\n",
    "        model.load_state_dict(state)\n",
    "        return model\n",
    "    except Exception:\n",
    "        if isinstance(state, dict):\n",
    "            # common keys\n",
    "            for k in (\"model_state_dict\", \"state_dict\", \"model\"):\n",
    "                if k in state:\n",
    "                    try:\n",
    "                        model.load_state_dict(state[k])\n",
    "                        return model\n",
    "                    except Exception:\n",
    "                        continue\n",
    "    raise RuntimeError(\"Failed to load checkpoint into model - unsupported format\")\n",
    "\n",
    "# If .pth: rebuild nn.Module; if .ptl: load TorchScript and wrap\n",
    "if CKPT_TYPE == \"pth\":\n",
    "    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=NUM_CLASSES)\n",
    "    state = torch.load(CKPT, map_location=\"cpu\")\n",
    "    try:\n",
    "        model = safe_load_state_dict_into(model, state)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not load state_dict into timm model:\", e)\n",
    "    model.eval().to(DEVICE)\n",
    "    is_script = False\n",
    "else:\n",
    "    # load TorchScript / lite\n",
    "    script_mod = torch.jit.load(CKPT, map_location=\"cpu\")\n",
    "    script_mod.eval()\n",
    "    class ScriptWrapper(torch.nn.Module):\n",
    "        def __init__(self, script_mod):\n",
    "            super().__init__()\n",
    "            self.script_mod = script_mod\n",
    "        def forward(self, x):\n",
    "            if x.dim() == 3:\n",
    "                x = x.unsqueeze(0)\n",
    "            # some mobile modules expect channels_last; make contiguous but keep robust\n",
    "            try:\n",
    "                x = x.contiguous(memory_format=torch.channels_last)\n",
    "            except Exception:\n",
    "                x = x.contiguous()\n",
    "            return self.script_mod(x)\n",
    "    model = ScriptWrapper(script_mod).to(DEVICE)\n",
    "    is_script = True\n",
    "\n",
    "# params & size\n",
    "def count_params(m):\n",
    "    try:\n",
    "        return sum(p.numel() for p in m.parameters())\n",
    "    except Exception:\n",
    "        try:\n",
    "            sd = m.state_dict()\n",
    "            return sum(v.numel() for v in sd.values())\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "params_total = count_params(model if not is_script else script_mod)\n",
    "print(\"Total params:\", params_total if params_total is not None else \"unknown (script/prepacked)\")\n",
    "\n",
    "ckpt_size_mb = Path(CKPT).stat().st_size / (1024*1024)\n",
    "print(\"Checkpoint size (MB):\", f\"{ckpt_size_mb:.3f}\")\n",
    "\n",
    "# FLOPs: prefer ptflops on nn.Module; for script attempt wrapper; fallback to thop\n",
    "if HAS_PT:\n",
    "    try:\n",
    "        # ptflops expects (C,H,W)\n",
    "        flops, params_pt = get_model_complexity_info(model, (INPUT_SIZE[0], INPUT_SIZE[1], INPUT_SIZE[2]),\n",
    "                                                    as_strings=False, print_per_layer_stat=False)\n",
    "        if flops is not None:\n",
    "            print(\"FLOPs:\", f\"{int(flops):,}\", \"->\", f\"{flops/1e9:.4f}\", \"GFLOPs\")\n",
    "        else:\n",
    "            print(\"ptflops returned None\")\n",
    "    except Exception as e:\n",
    "        print(\"ptflops failed:\", e)\n",
    "\n",
    "elif HAS_THOP:\n",
    "    try:\n",
    "        dummy = torch.randn(1, *INPUT_SIZE).to(DEVICE)\n",
    "        macs, params_thop = thop_profile(model, inputs=(dummy,), verbose=False)\n",
    "        flops_est = macs * 2\n",
    "        print(\"thop -> MACs:\", f\"{int(macs):,}\", \"Est FLOPs:\", f\"{int(flops_est):,}\", f\"({flops_est/1e9:.4f} GFLOPs)\")\n",
    "    except Exception as e:\n",
    "        print(\"thop failed:\", e)\n",
    "else:\n",
    "    print(\"ptflops/thop not installed; skipping FLOPs estimation\")\n",
    "\n",
    "# torchinfo summary (only for nn.Module CPU)\n",
    "if HAS_INFO and not is_script:\n",
    "    try:\n",
    "        summary(model.cpu(), input_size=(1, *INPUT_SIZE), col_names=(\"input_size\", \"output_size\", \"num_params\"))\n",
    "    except Exception as e:\n",
    "        print(\"torchinfo failed:\", e)\n",
    "\n",
    "# latency & throughput\n",
    "def measure(device, iters=50, warmup=10, batch=1):\n",
    "    model.to(device)\n",
    "    dummy = torch.randn(batch, *INPUT_SIZE).to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy)\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "        for _ in range(iters):\n",
    "            _ = model(dummy)\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "    avg_ms = (t1 - t0) / iters * 1000\n",
    "    imgs_per_s = 1000 / avg_ms * batch if avg_ms > 0 else float(\"inf\")\n",
    "    return avg_ms, imgs_per_s\n",
    "\n",
    "print(\"Measuring on device:\", DEVICE)\n",
    "lat_ms, ips = measure(DEVICE, iters=30, warmup=5, batch=1)\n",
    "print(f\"Latency avg: {lat_ms:.2f} ms, Throughput: {ips:.1f} img/s\")\n",
    "\n",
    "# GPU memory peek\n",
    "if DEVICE.type == \"cuda\":\n",
    "    import gc\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "    with torch.no_grad():\n",
    "        _ = model(torch.randn(1, *INPUT_SIZE).to(DEVICE))\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"CUDA allocated (MB):\", torch.cuda.memory_allocated() / 1024**2)\n",
    "    print(\"CUDA reserved (MB):\", torch.cuda.memory_reserved() / 1024**2)\n",
    "\n",
    "# short profiling (best-effort)\n",
    "try:\n",
    "    import torch.profiler\n",
    "    activities = [torch.profiler.ProfilerActivity.CPU]\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        activities.append(torch.profiler.ProfilerActivity.CUDA)\n",
    "    with torch.profiler.profile(activities=activities, record_shapes=True, with_stack=False) as prof:\n",
    "        model.to(DEVICE)\n",
    "        inp = torch.randn(1, *INPUT_SIZE).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            model(inp)\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "except Exception as e:\n",
    "    print(\"profiler skipped:\", e)\n",
    "\n",
    "# Done\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
